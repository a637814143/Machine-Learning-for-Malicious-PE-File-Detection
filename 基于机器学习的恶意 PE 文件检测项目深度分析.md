# 基于机器学习的恶意 PE 文件检测项目总结

## 一、项目背景与问题重要性

### 1.1 问题背景

在 Windows 平台上，绝大多数可执行程序都采用 PE（Portable Executable）文件格式。恶意软件（木马、蠕虫、勒索软件等）往往也以 PE 文件形式传播。传统杀毒软件主要依赖 **特征码 / 签名** 来识别恶意样本，这种方式有两个明显问题：

1. 对 **已知样本及其轻微变种** 检测效果很好；
2. 对 **变种、混淆、加壳、零日样本** 经常失效，需要人工更新签名库。

随着恶意样本数量爆炸式增长，仅靠人工维护的签名库难以应对。因此需要一种 **基于机器学习的检测方式**：通过分析 PE 文件本身的静态特征，让模型自动学习“恶意文件”和“良性文件”在特征层面的差异，从而对未知样本进行判别，而不依赖具体签名。

### 1.2 本项目解决的问题

本项目要解决的问题可以概括为：

> **如何基于 Windows PE 文件的静态特征，利用机器学习自动判断一个文件是恶意还是良性，并构建一个从特征提取到模型训练、到批量检测和报告生成的完整系统。**

解决下列问题：

- 如何筛选出真正的 PE 文件；
- 如何系统化、自动化地从 PE 文件中提取有用的静态特征；
- 如何把这些结构化／半结构化特征（JSONL）统一转成固定长度的数值向量；
- 如何选择合适的机器学习模型（项目用的是 LightGBM）来进行恶意 / 良性二分类；
- 如何把训练好的模型集成到 GUI / Web 服务中，实现实际可用的恶意文件检测工具。

---

## 二、项目解决方案概览

### 2.1 总体思路

项目采用 **“静态分析 + 机器学习”** 的路线，整体流程如下：

1. **特征提取**  
   使用 `pefile`、`lief` 等库解析 PE 文件结构，提取出：
   
   - 字节级统计特征（直方图、熵等）  
   - 字符串相关特征  
   - PE 头部信息、节信息、数据目录情况  
   - 导入 / 导出表等 API 使用信息  
   这些特征被保存成 JSON / JSONL 格式。
   
2. **特征向量化**  
   编写向量化模块，把 JSON 结构化特征统一转换为一个 **固定长度的数值向量（2381 维）**，包括：  
   
   - 直接使用的数值特征（如大小、计数、版本号等）  
   - 归一化的统计特征（直方图、频率分布）  
   - 利用 **特征哈希** 把类别型特征（字符串 / 列表）映射到固定维度的向量上。
   
3. **模型训练**  
   使用 LightGBM（梯度提升树框架）对向量化特征进行二分类训练：  
   
   - 输入：`X` 为 2381 维特征向量，`y` 为 0/1 标签（良性/恶意）  
   
   - 采用适合恶意检测的参数配置（较多叶子数 + 子采样 + 正则化）  

   - 使用 AUC 作为主要优化指标  
   
   - 支持早停和参数覆盖
   
   - 完整的配置如下：
   
     ```
     {
         "boosting_type": "gbdt",
         "objective": "binary",
         "metric": "auc",
         "num_leaves": 2048,
         "learning_rate": 0.05,
         "feature_fraction": 0.1,
         "bagging_fraction": 0.5,
         "bagging_freq": 1,
         "min_data_in_leaf": 50,
         "lambda_l1": 1.0,
         "lambda_l2": 1.0,
         "max_bin": 255,
         "verbosity": -1,
     }
     ```
   
     
   
4. **预测与部署**  
   - 把训练好的模型集成到 PyQt5 GUI 和 Flask Web 服务中；
   - 支持对文件夹进行批量扫描：自动特征提取 → 向量化 → 预测；
   - 输出 HTML/Markdown 报告，展示每个样本的恶意概率、风险评级、统计信息等；
   - GUI 中提供“阈值选择”，可以动态调整判断恶意的阈值，权衡查全率和误报率。

### 2.2 更自动化的、低门槛使用、集成 API 

项目不仅是一个算法 demo，而是一个相对完整的 **检测系统原型**，特点包括：

- 从原始 `.exe` 文件到特征、向量、模型训练、批量检测、报告生成；
- 提供桌面 GUI，便于非专业用户操作；
- 提供服务端接口（Flask），便于集成到其他系统。

---

## 三、项目效果与评估方式

### 3.1 效果评价的角度

项目主要从以下几个维度评价效果：

- **AUC（ROC 曲线下面积）**：作为训练过程的主要指标；
- **准确率（Accuracy）**：在某个固定阈值下，预测正确的比例；
- **误报率（False Positive Rate）**：良性样本被错误判为恶意的比例；
- GUI 中通过阈值选择帮助观察不同阈值下的性能变化，以便在：
  - 特别关注“不要放过任何恶意样本”的场景下，尽量提高查全率；
  - 特别关注“不要误杀正常软件”的场景下，尽量降低误报率。

### 3.2 模型效果的解读

项目默认使用的特征集合和 LightGBM 的配置是基于恶意 PE 检测领域已有成熟实践“移植”过来的，在公开研究中这套组合通常可以取得较高的 AUC 和不错的准确率。

- 描述：训练集 / 验证集 / 测试集 7 : 2 : 1；
- 统计：valid: auc=0.984894

---

## 四、特征提取：字段、维度与含义（重点）

本项目的特征设计几乎完全对齐一个广泛使用的恶意 PE 数据集（EMBER）的特征方案，因此是有充分实践经验支撑的。

整体上，特征可以分为几大类：

1. 文件级别的字节统计特征  
2. 字符串相关特征  
3. PE 通用信息（general）  
4. PE 头部信息（header）  
5. 节区信息与数据目录信息（section / datadirectories）  
6. 导入 / 导出 API 特征（imports / exports）

下面逐类说明含义和作用。

### 4.1 文件哈希与基础信息

- **sha256 / md5**
  
  - 作用：唯一标识一个样本，便于查重和管理；
  - 不直接参与机器学习建模（更多用于报告和样本管理）。
- **label**
  
  - 标签：0 = 良性，1 = 恶意；
  - 项目中通过文件路径是否包含“VirusShare”等关键字简单映射为恶意，其余作为良性；
  > VirusShare 仅包含恶意
  - 在正式实验中通常需要使用已有标注好的数据集，例如使用 EMBER 官方数据集，项目已经完成对 EMBER 公布的数据集兼容

### 4.2 字节直方图（histogram）

- **维度**：256 维（每个字节值 0–255 一个维度）；
- **含义**：统计整个文件中每种字节值出现的频率；
- **作用**：
  - 反映文件整体内容分布；
  - 高压缩 / 加密的数据往往呈现接近均匀的字节分布；
  - 一些特定类型文件（如文本、多媒体）则有明显偏向某些字节范围。

在实现上：

- 遍历文件的每一个字节，计数；
- 最终除以总字节数做归一化，得到频率分布。

### 4.3 字节熵二维直方图（byteentropy）

- **维度**：原始是 16×16 的二维直方图，展平成 256 维向量；
- **构造方法**：
  1. 按固定窗口（2048 字节）滑动扫描整个文件；
  2. 对每个窗口计算：
     - 该窗口的平均字节值（0–255）；
     - 该窗口的熵（0–8 bit）；
  3. 将平均字节值和熵分别量化到 16 个桶（0–15）；
  4. 在 16×16 的格子上累加计数，最后展成 256 维向量并归一化。

- **作用**：
  - 同时结合了字节内容和随机性；
  - 能够识别“某些区域熵高、某些区域熵低”的结构；
  - 对加壳、混淆、嵌入数据段等恶意行为很敏感。

### 4.4 字符串特征（strings）

项目会扫描文件中所有连续的可打印字符序列（通常长度 ≥4），然后计算以下特征：

- **numstrings**
  - 检测到的字符串总数；
  - 正常程序往往包含较多字符串（调试信息、路径、日志等），某些恶意样本会故意减少或加密字符串。

- **avlength**
  - 字符串平均长度；
  - 可以一定程度上反映字符串信息量。

- **printables**
  - 所有字符串中可打印字符的总数量；
  - 为后续的字符分布做归一化使用。

- **printabledist**
  - 长度 96 的向量，对 ASCII 中可打印字符（0x20–0x7F）的统计；
  - 向量每一维表示某个字符出现的次数；
  - 在向量化阶段会除以 `printables`，变成频率分布。

- **entropy**
  - 基于所有字符串字符的整体熵；
  - 值越高说明字符串内容越“乱”，可能经过编码或加密。

- **paths / urls / registry**
  - 分别统计字符串中匹配到的：
    - 路径模式（如 `C:\Windows\System32\...`）数量；
    - URL 模式（如 `http://...`、`https://...`）数量；
    - 注册表路径模式（如 `HKEY_LOCAL_MACHINE\...`）数量；
  - 这些都与恶意行为相关：恶意样本常嵌入网址、命令控制服务器地址、注册表自启动键等。

- **MZ**
  - 文件内出现子串 `"MZ"` 的次数；
  - 有时用来判断文件中是否嵌套了其他 PE 文件等。

- **strings_per_kb**
  - 每 KB 文件大小中平均字符串数量；
  - 结合 `numstrings` 和文件大小更公平地比较不同大小的文件。

此外，项目还会在报告中额外存储：

- 一小部分示例 URL / 路径；
- 若干最长字符串；
- 若干出现频率最高的字符；
- 包含可疑关键字的字符串（如 `powershell`, `cmd.exe`, `regsvr32` 等）。

这些示例不一定全部进模型，但在报告中对人工分析帮助很大。

### 4.5 PE 通用信息（general）

**general** 模块包含若干和 PE 文件整体结构相关的特征，全部为数值型，例如：

- 文件大小 `size`；
- 映像大小 `vsize`（内存中加载后总大小）；
- 是否包含调试信息 `has_debug`；
- 导出函数数量 `exports`；
- 导入函数数量 `imports`；
- 是否存在重定位表 `has_relocations`；
- 是否存在资源表 `has_resources`；
- 是否有数字签名 `has_signature`；
- 是否有 TLS 表 `has_tls`；
- 符号表条目数 `symbols`。

这些特征来自 `lief` 对 PE 的解析。直观解释：

- **有数字签名** 的 PE 更可能是正规软件；
- **资源表**、**重定位表** 的存在与否会影响可执行文件结构；
- 导入 / 导出数量能区分DLL、驱动程序、普通 EXE 等类型；
- 恶意软件往往会有一些结构异常，如：没有签名、资源表异常、导入表怪异等。

### 4.6 PE 头部信息（header）

头部信息主要分为两个部分：COFF 头和可选头（Optional Header）。

#### 4.6.1 COFF 头（header.coff）

- **timestamp**：编译时间戳（整数）；
- **machine**：体系结构，比如 x86、x64 等，对应一个字符串枚举；
- **characteristics**：文件标志，如“可执行文件”“DLL”“系统文件”等，是一组标志位列表。

这些特征的意义在于：

- 恶意样本经常伪造时间戳，或者相同家族样本具有高度相似的时间戳分布；
- 某些架构或标志组合在正常软件中很少出现，但在恶意样本中可能较多。

在向量化时：

- timestamp 直接作为数值特征；
- machine 和 characteristics 通过特征哈希转为小维度向量。

#### 4.6.2 可选头（header.optional）

包含 PE 的版本和运行环境信息，例如：

- **subsystem**：子系统（GUI、控制台、驱动等），字符串；
- **dll_characteristics**：DLL 附加标志列表（如是否兼容 ASLR、是否启用 DEP）；
- **magic**：PE 类型（PE32 / PE32+）；
- 一系列 **版本字段**：
  - 链接器主 / 次版本号；
  - 映像版本号；
  - 所需操作系统版本号；
  - 子系统版本号等；
- 一些大小类字段：
  - sizeof_code；
  - sizeof_headers；
  - sizeof_heap_commit 等。

在向量化时：

- 数值字段（版本号、大小）直接放入向量；
- 字符串 / 列表字段（subsystem, dll_characteristics, magic）通过特征哈希编码。

这些信息可以帮助模型识别“看起来不太正常的 PE 文件”。例如某些恶意样本会仿冒系统文件，但版本号、子系统等字段与真实系统文件并不一致。

### 4.7 节区信息与数据目录（section & datadirectories）

#### 4.7.1 节区（section）

每个 PE 有若干节区（`.text`, `.rdata`, `.data`, `.rsrc`, …），项目提取以下信息：

- 每个节区的：
  - 名称 `name`；
  - 原始大小 `size`；
  - 虚拟大小 `vsize`；
  - 熵 `entropy`；
  - 权限和属性 `props`（是否包含代码、数据，是否可读/写/执行等）。

此外，还统计了一些 **整体统计量**：

- 节区总数；
- 大小为 0 的节区数；
- 无名称节区数；
- 具有可执行权限的节区数；
- 具有写权限的节区数。

并构造了几个哈希特征：

- 节区名称与大小的散列向量；
- 节区名称与熵的散列向量；
- 节区名称与虚拟大小的散列向量；
- 入口点所在节区名称和其属性的散列。

这些节区特征非常重要，因为：

- 恶意软件常常添加额外节区，或使用异常命名；
- 某个节区同时具有“可写 + 可执行”权限在正常程序中很少见；
- 高熵节区可能是加密的 shellcode 或打包内容。

#### 4.7.2 数据目录（datadirectories）

PE 可选头中有若干数据目录，如：

- 导入表、导出表；
- 资源表；
- 调试信息；
- 证书表；
- 异常表等。

项目对每个目录项提取两个数值：

- `size`：该目录的大小；
- `virtual_address`：虚拟地址。

并固定遍历前 15 个目录项，不足的部分用 0 填充。这样每个样本得到 30 维的目录特征向量。

这些特征可以反映：

- 文件中是否包含资源（图标、对话框等）；
- 是否有签名证书；
- 是否包含异常表、TLS 等高级结构。

### 4.8 导入 / 导出 API 特征（imports / exports）

#### 4.8.1 导入表（imports）

结构大致为：

```json
"imports": {
  "kernel32.dll": ["CreateFileW", "ReadFile", ...],
  "user32.dll": ["MessageBoxW", ...],
  ...
}
```

向量化方式：

1. 把所有导入 DLL 名称收集成集合，用一个 256 维哈希向量表示；
2. 把所有“库名:函数名”组合成字符串列表，比如 `"kernel32.dll:CreateFileW"`，用 1024 维哈希向量表示。

意义：

- 不同类型程序会有不同的导入模式；
- 恶意软件常导入网络、进程注入、注册表操作等敏感 API；
- 有些恶意软件相反几乎不导入 API，依赖壳或动态加载，这也会在特征上体现为“模式异常”。

#### 4.8.2 导出表（exports）

导出表是 PE 向外提供的函数接口，例如 DLL 导出的 API：

```
"exports": ["DllMain", "SomeFunc", ...]
```

项目将所有导出函数名列表通过 128 维哈希向量表示。典型 EXE 通常没有导出函数，而 DLL 和某些恶意伪装 DLL 则会有，这也能产生有区分度的信号。

------

## 五、特征向量化处理流程

### 5.1 总体目标

- 输入：每个样本是一份 JSON / JSONL 文件，包含上述各种特征字段；
- 输出：一个固定长度为 **2381 维+** 的数值向量；
- 要求：
  - 不同样本的特征含义位置一致；
  - 能处理字段缺失（解析失败等情况）；
  - 能处理长度可变的特征（例如 API 列表、节区列表、字符分布）；

### 5.2 向量化的主要步骤

1. **初始化向量**
    每个样本先分配一个全 0 的 2381 维数组。

2. **数值型特征直接写入**
    例如：

   - histogram（256 维） → 归一化 → 写入；
   - byteentropy（256 维） → 归一化 → 写入；
   - strings 中的基本计数特征（numstrings、avlength、printables、entropy、paths、urls、registry、MZ 等）；
   - strings.printabledist（96 维） → 除以 printables 做归一化；
   - general 的 10 个数值字段；
   - header.optional 的 11 个数值字段；
   - datadirectories 的 size 和 virtual_address（共 30 维）。

3. **类别与列表特征使用特征哈希（Feature Hashing）**
    特征哈希的思想是：

   > 把字符串/类别映射到一个固定长度的向量索引上进行累加。
   >  这样可以在不维护巨大词典的情况下，将可变长的类别特征编码为定长向量。

   在本项目中，特征哈希用于：

   - header.coff.machine（10 维）；
   - header.coff.characteristics（10 维）；
   - header.optional.subsystem（10 维）；
   - header.optional.magic（10 维）；
   - header.optional.dll_characteristics（10 维）；
   - section 的若干哈希向量（节名称+大小、节名称+熵、节名称+虚拟大小、入口节名、入口节属性）；
   - imports 的 DLL 名列表（256 维）；
   - imports 的“库:函数”组合（1024 维）；
   - exports 的函数名列表（128 维）。

4. **缺失值处理**

   - 使用 `features.get("xxx", 默认值)` 的方式获取字段；
   - 若某个字段不存在或解析失败，则：
     - 数值型设为 0；
     - 列表型设为空列表；
     - 字符串型设为空字符串；
   - 经过特征哈希和直接写入处理后，缺失字段对向量的贡献自然是全 0。

   对树模型而言，“0”本身既表示缺失又表示“无该特征”，不会造成数值上不合理。

5. **输出格式**

   对所有样本生成的向量最终打包成 `.npz` 文件，通常包含：

   - `X`：形如 `(N, 2381)` 的特征矩阵；
   - `y`：长度为 `N` 的标签向量。

   训练模块直接读取这些 `.npz` 文件进行建模。

------

## 六、模型训练与参数设置

### 6.1 模型选择：LightGBM

考虑到特征是结构化 / 稀疏的高维向量（2381 维，包括大量哈希向量），而样本量可能比较大，选择 LightGBM 有几个好处：

1. **对高维稀疏特征表现好**：梯度提升树天然适合这类特征；
2. **训练速度快**：基于直方图算法和高效实现；
3. **原生支持 AUC、早停等功能，调参方便**；
4. 在恶意 PE 检测领域已有成功实践，经验丰富。

### 6.2 训练代码与流程

主要训练逻辑在 `core/modeling/trainer.py` 中，典型流程：

1. 从 `.npy` / `.npz` 文件中加载训练数据 `X_train, y_train`，以及可选的验证数据 `X_val, y_val`；
2. 构造 LightGBM 的数据集对象 `lgb.Dataset`；
3. 使用一个专门的配置函数（例如 `build_ember_lightgbm_config`）生成一组默认参数；
4. 调用 `lgb.train` 开始训练：
   - 可以指定迭代轮数 `num_boost_round`；
   - 可以指定 `early_stopping_rounds` 用于基于验证集的早停；
   - 可以传入回调以便向 GUI 报告训练进度。

训练完成后：

- 把模型保存为 LightGBM 文本模型文件（如 `model.txt`）；
- GUI 里可以选择这个模型进行后续批量检测。

### 6.3 超参数配置

默认参数大致为：

- **树结构相关**
  - `num_leaves = 2048`：叶子节点数，控制树复杂度；
  - `max_bin = 255`：直方图桶数（与字节类特征的取值范围比较匹配）；
  - `min_data_in_leaf = 50`：叶子结点最少样本数，防止过拟合。
- **正则化**
  - `lambda_l1 = 1.0`；
  - `lambda_l2 = 1.0`。
- **采样**
  - `feature_fraction = 0.1`：每棵树随机选择 10% 特征；
  - `bagging_fraction = 0.5`：每轮训练使用 50% 样本；
  - `bagging_freq = 1`：每轮都进行 bagging。
- **学习率与迭代**
  - `learning_rate = 0.05`；
  - `num_boost_round = 600`（如果设置早停则实际迭代数会更少）；
  - `early_stopping_rounds = 50`（如使用验证集）。
- **其他**
  - `metric = "auc"`：使用 AUC 作为评估指标；
  - `num_threads`：默认使用全部 CPU 核心；
  - `verbosity = -1`：减少日志输出。

### 6.4 阈值与评估

- 模型输出的是一个 **“恶意概率分数”（0~1）**；
- GUI 中允许用户通过滑块设置阈值，例如 0.5、0.8 等；
- 根据不同阈值，可以计算：
  - 准确率；
  - 误报率；
  - 漏报率（1-召回率）；
- 在实际部署中，可以：
  - 提供多个档位（“高灵敏度”“平衡”“低误报”等）；
  - 或给出恶意评分，再根据业务需求定义处理策略。

------

## 七、理论依据与原理说明

### 7.1 静态特征检测 vs 动态分析

- **静态检测**：不运行样本，仅通过分析文件结构和内容提取特征；
  - 优点：速度快、安全、不需要执行环境；
  - 缺点：遇到复杂混淆或加壳时有一定困难。
- **动态分析**：在沙箱中运行样本，观察行为；
  - 优点：对混淆、加壳更鲁棒；
  - 缺点：开销大、难以大规模部署。

本项目采用静态特征 + 机器学习的方式，属于在工程和效果之间折中比较好的方案——在**大规模批量检测**场景下尤其合适。

### 7.2 特征工程的理论支撑

- **字节直方图 / 熵**
   思路：恶意软件常通过压缩、加密、打包等方式隐藏自身逻辑，这会显著改变字节分布与随机性。熵越高、分布越均匀，越可能是某种加壳或加密区域。

- **字符串特征**
   许多恶意样本嵌入 URL、命令、注册表路径、文件路径等字符串。一方面这些是恶意行为的直接线索，另一方面恶意样本有时会“过度隐藏”这些信息导致字符串数量异常低。对这些字符串做统计和模式匹配可以帮助模型识别恶意行为。

- **PE Header 与节区特征**
   PE 头部和节区布局是编译器、链接器以及开发习惯共同作用的结果。正常软件往往遵守某些隐含规则，而恶意软件由于自动生成、壳处理等往往不完全遵守。例如：

  - 节区数量异常多或名称奇怪；
  - 某些节区同时可写可执行；
  - 文件大小、映像大小与节区信息不匹配；
  - 不必要地存在某些数据目录或缺失常见数据目录。

- **导入 / 导出表特征**
   Windows API 调用是恶意行为的重要线索。例如：

  - 使用网络相关 API（WinINet、WinHTTP 等）进行 C2 通信；
  - 使用进程注入相关 API（OpenProcess、WriteProcessMemory 等）；
  - 使用注册表、服务管理相关 API 持久化。

  通过统计“导入的库”和“导入的 API 组合”，模型可以学习到典型恶意行为的模式。

### 7.3 特征哈希（Feature Hashing）的合理性

面对大量类别特征（如 API 名、DLL 名、节区名等），如果为每个类别分配一个独立维度，会导致维度爆炸且难以管理。特征哈希的思路是：

- 对每个类别字符串做哈希取模，映射到一个预设长度的向量索引；
- 数据只需存储这一个小向量，训练时同样有效；
- 维度越大，哈希冲突越少，表示能力越强；维度越小，模型越紧凑。

在恶意检测任务中，这种近似表示通常足够区分不同行为模式，可以兼顾性能和效果。

### 7.4 梯度提升树

- 特征是稀疏高维且混合类型（计数、布尔、类别哈希）；
- 梯度提升树（GBDT / LightGBM）对这类特征非常友好：
  - 不需要对数值特征做复杂归一化；
  - 能够自动建模特征之间的非线性关系；
  - 训练速度快、效果稳定、调参经验丰富；
- 相比深度神经网络，GBDT 对于这类结构化特征往往更容易获得高性能，且需要的样本量更小。

### 7.5 阈值与代价敏感的决策

在安全场景中：

- **漏报一个恶意样本** 可能造成严重后果；
- **误报一个良性样本** 可能影响用户体验或业务可用性。

因此，不能只看准确率，而需要通过阈值控制 **召回率 / 误报率**。本项目通过 GUI 把阈值显式暴露给用户，让最终使用者根据自己的场景选择合适的策略，这就是一种简单但有效的“代价敏感决策”。

## 八、 动态检测详细信息

### **8.1 动态行为采集模块设计**

- 架构图：用户上传样本 → Flask → Frida → 行为日志 → 返回 JSON
- 说明使用 Frida 动态插桩，实现对文件、网络、注册表、进程四类关键行为的监控；

### **8.2 Frida Hook 实现**

- 简略概述：
  - 文件操作 Hook（CreateFile、WriteFile、DeleteFile…）
  - 网络连接 Hook（connect，解析出 IP 和端口）
  - 注册表操作 Hook（RegCreateKeyEx、RegSetValueEx、RegDeleteKey…）
  - 进程创建 Hook（CreateProcessW）
- onEnter/onLeave 机制；

### **8.3 Python 控制流程**

-  `frida.spawn` ->`attach`->`create_script`->`resume`->`kill` 的调用顺序；
-  `on_message` 回调收集事件，并分类汇总。

### **8.4 安全性与隔离性分析**

- 该系统部署在虚拟机中，避免执行恶意程序对真实系统造成破坏；
- PC宿主机设置类似Linux的0400权限 -> 中转Linux，防止感染（Linux无法执行exe） -> PC虚拟机